df_dict_index = grep(table_dict, names(dfs_dict))
df_dict = dfs_dict[[df_dict_index]] %>% select(cols_dict)
# join them
merged = merge(df, df_dict, by.x = col_attri, by.y = cols_dict[[1]], all.x = T, all.y=F)
print(paste0("joind the tables: ", table_attri, " and ", table_dict))
print(paste0("    on the columns ", col_attri, " and ", cols_dict[[1]]))
print(paste0("    Resulting table is has ", dim(merged)[[1]], " rows, and ", dim(merged)[[2]], " columns"))
print("")
joined_tables[[i]] = merged
}
return(joined_tables)
}
#' join each table in a list of tables from the dict on the shape
join_descriptions_shape = function(list_of_dfs_dict, shape) {
final_shape = shape
# test_list = vector("list"); i = 1
for(table_dict in list_of_dfs_dict){
# test_list[[i]] = final_shape
print(nrow(final_shape))
print(nrow(table_dict))
final_shape = join_on_iffikodex(final_shape, table_dict)
# i = i+1
}
return(final_shape)
}
select_cols = function(df, attri, joins){
# the directly selected columns
column_names = attri
# the columns we want from the dictionary
cols_dict = vector(length = length(joins))
for (i in seq_along(joins)) {
col = sapply(joins[[i]], function(x) split_and_return(x), USE.NAMES = F) %>% .[[2]]
cols_dict[[i]] = col
}
final_cols = c("PIFF_ID", column_names, cols_dict)
# select them
df = df %>% select(final_cols)
return(df)
}
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
shape = shape,
attri=attri)
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
shape = shape,
attri=attri)
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = "."
shape = shape,
attri=attri)
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = ".",
shape = shape,
attri=attri)
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = ".",
shape = shape,
attri=attri)
make_shapefile = function(database_dir=NULL,
attribute_database_name=NULL,
dictionary_database_name=NULL,
shapefile=NULL,
attri=NULL,
joins="") {
# establish connections
conns = set_connection(database_dir)
# set the right ones
# there are some issues with indexing the list, for some reason we need to index conns with [[]]
# to maintain a valid and open connection
index_attr = which(grepl(attribute_database_name, names(conns)))
if (!is.null(dictionary_database)) {
index_dict = which(grepl(dictionary_database_name, names(conns)))
}
attr_database_conn = conns[[index_attr]]
if (!is.null(dictionary_database)) {
dict_database_conn = conns[[index_dict]]
}
# the table names are the attributes we can query
# Especially the one in the attributes table are interesting
table_names_attr = make_vector_table_names(attr_database_conn)
if (!is.null(dictionary_database)) {
table_names_dict = make_vector_table_names(dict_database_conn)
}
# create a csv file of the names of the databases
# write_csvs(table_names = table_names, database_dir = database_dir)
# make a list of dataframes(tables) for the attributes database
dfs_attr = make_list_dataframes(attr_database_conn)
# make a list of dataframes(tables) for the dictionary database
if (!is.null(dictionary_database)) {
dfs_dict = make_list_dataframes(dict_database_conn)
}
# check for each dataframe if they have an id and subid column
log_vec = check_id(dfs_attr)
# for the rest create the iffi index for the attribute tables
dfs_attr_iffi = create_iffi_index(dfs_attr, log_vec)
# find the tables that we can join directly
tables_to_append_diretly = find_tables(dfs_attr_iffi, attri)
### join those tables
# read the shape
shape = read_shape(shapefile)
shape_joined_attri = join_shape_attributes(shape, tables_to_append_diretly, dfs_attr_iffi)
# make the joins to the dictionary
if (!is.null(dictionary_database)) {
joined_dicionary_tables_with_iffi_kodex = join_descriptions(joins, dfs_attr_iffi, dfs_dict)
}
# join them to the shape
if (!is.null(dictionary_database)) {
final_joined = join_descriptions_shape(joined_dicionary_tables_with_iffi_kodex, shape_joined_attri)
}
# filter the columns we wanted
final_selected = select_cols(final_joined, attri, joins)
return(final_selected)
}
# the necessasry paths
database_folder = "../inst/extdata"
attribute_db = "test"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
shape = shape,
attri=attri)
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = ".",
shape = shape,
attri=attri)
# the necessasry paths
database_folder = "../inst/extdata"
attribute_db = "test"
dictionary_db = "dict_db"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
traceback()
library(iffitoR)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(iffitoR)
# the necessasry paths
database_folder = "../inst/extdata"
attribute_db = "test"
dictionary_db = "dict_db"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
ttraceback()
traceback()
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
traceback()
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
#' Main Function
#' @import dplyr
#' @import RODBC
#' @import tools
#' @import sf
#' @import stringr
#' @description
#' Generate a shapefile from a given spatial data-object and attributes as
#' produced by a query on the iffi database
#'
#' @return An sf-oject
#'
#' @param database_dir Path to the directory of the databases
#' @param attribute_database_name Name without extension of the attributes database
#' @param dictionary_database_name Name without extension of the dictionary database
#' @param shapefile A shape that cointains the iffi_kodex in a column called PIFF_ID
#' @param attri A vector of attributes to query directly from the attributes database
#' @param join A named list of the tables that need to be joined in order to get the desciptions from the dictionary
#' @export
#' @examples
#' \dontrun{
#'database_dir = "data/database/",
#'attribute_database_name = "tbl_frane",
#'dictionary_database_name = "diz_frane",
#'shapefile = "data/Shapefiles/IFFI10_5.shp",
#'attri = c(
#'   "anno_min",
#'   "anno_max",
#'   "mese_min",
#'   "mese_max",
#'   "giorno_min",
#'   "giorno_max"
#'),
#'joins = list(
#'   "tbl_frane.Geologia.litologia" = c(
#'      "diz_frane.diz_litologie.litologia",
#'      "diz_frane.diz_litologie.nome_litologia"
#'   ),
#'
#'   "tbl_frane.clas_ii_liv.movimento" = c(
#'      "diz_frane.diz_movimenti.movimento",
#'      "diz_frane.diz_movimenti.nome_movimento"
#'   ),
#'   "tbl_frane.Uso_Suolo.uso_suolo" = c(
#'      "diz_frane.diz_usi_suolo.uso_suolo",
#'      "diz_frane.diz_usi_suolo.nome_uso_suolo"
#'   )
#'),
#'plot = FALSE
#')
#'}
make_shapefile = function(database_dir=NULL,
attribute_database_name=NULL,
dictionary_database_name=NULL,
shapefile=NULL,
attri=NULL,
joins="") {
# establish connections
conns = set_connection(database_dir)
# set the right ones
# there are some issues with indexing the list, for some reason we need to index conns with [[]]
# to maintain a valid and open connection
index_attr = which(grepl(attribute_database_name, names(conns)))
if (!is.null(dictionary_database_name)) {
index_dict = which(grepl(dictionary_database_name, names(conns)))
}
attr_database_conn = conns[[index_attr]]
if (!is.null(dictionary_database_name)) {
dict_database_conn = conns[[index_dict]]
}
# the table names are the attributes we can query
# Especially the one in the attributes table are interesting
table_names_attr = make_vector_table_names(attr_database_conn)
if (!is.null(dictionary_database_name)) {
table_names_dict = make_vector_table_names(dict_database_conn)
}
# create a csv file of the names of the databases
# write_csvs(table_names = table_names, database_dir = database_dir)
# make a list of dataframes(tables) for the attributes database
dfs_attr = make_list_dataframes(attr_database_conn)
# make a list of dataframes(tables) for the dictionary database
if (!is.null(dictionary_database_name_name)) {
dfs_dict = make_list_dataframes(dict_database_conn)
}
# check for each dataframe if they have an id and subid column
log_vec = check_id(dfs_attr)
# for the rest create the iffi index for the attribute tables
dfs_attr_iffi = create_iffi_index(dfs_attr, log_vec)
# find the tables that we can join directly
tables_to_append_diretly = find_tables(dfs_attr_iffi, attri)
### join those tables
# read the shape
shape = read_shape(shapefile)
shape_joined_attri = join_shape_attributes(shape, tables_to_append_diretly, dfs_attr_iffi)
# make the joins to the dictionary
if (!is.null(dictionary_database_name)) {
joined_dicionary_tables_with_iffi_kodex = join_descriptions(joins, dfs_attr_iffi, dfs_dict)
}
# join them to the shape
if (!is.null(dictionary_database_name)) {
final_joined = join_descriptions_shape(joined_dicionary_tables_with_iffi_kodex, shape_joined_attri)
}
# filter the columns we wanted
final_selected = select_cols(final_joined, attri, joins)
return(final_selected)
}
# the necessasry paths
database_folder = "../inst/extdata"
attribute_db = "test"
dictionary_db = "dict_db"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
traceback()
make_shapefile = function(database_dir=NULL,
attribute_database_name=NULL,
dictionary_database_name=NULL,
shapefile=NULL,
attri=NULL,
joins="") {
# establish connections
conns = set_connection(database_dir)
# set the right ones
# there are some issues with indexing the list, for some reason we need to index conns with [[]]
# to maintain a valid and open connection
index_attr = which(grepl(attribute_database_name, names(conns)))
if (!is.null(dictionary_database_name)) {
index_dict = which(grepl(dictionary_database_name, names(conns)))
}
attr_database_conn = conns[[index_attr]]
if (!is.null(dictionary_database_name)) {
dict_database_conn = conns[[index_dict]]
}
# the table names are the attributes we can query
# Especially the one in the attributes table are interesting
table_names_attr = make_vector_table_names(attr_database_conn)
if (!is.null(dictionary_database_name)) {
table_names_dict = make_vector_table_names(dict_database_conn)
}
# create a csv file of the names of the databases
# write_csvs(table_names = table_names, database_dir = database_dir)
# make a list of dataframes(tables) for the attributes database
dfs_attr = make_list_dataframes(attr_database_conn)
# make a list of dataframes(tables) for the dictionary database
if (!is.null(dictionary_database_name_name)) {
dfs_dict = make_list_dataframes(dict_database_conn)
}
# check for each dataframe if they have an id and subid column
log_vec = check_id(dfs_attr)
# for the rest create the iffi index for the attribute tables
dfs_attr_iffi = create_iffi_index(dfs_attr, log_vec)
# find the tables that we can join directly
tables_to_append_diretly = find_tables(dfs_attr_iffi, attri)
### join those tables
# read the shape
shape = read_shape(shapefile)
shape_joined_attri = join_shape_attributes(shape, tables_to_append_diretly, dfs_attr_iffi)
# make the joins to the dictionary
if (!is.null(dictionary_database_name)) {
joined_dicionary_tables_with_iffi_kodex = join_descriptions(joins, dfs_attr_iffi, dfs_dict)
}
# join them to the shape
if (!is.null(dictionary_database_name)) {
final_joined = join_descriptions_shape(joined_dicionary_tables_with_iffi_kodex, shape_joined_attri)
}
# filter the columns we wanted
final_selected = select_cols(final_joined, attri, joins)
return(final_selected)
}
devtools::load_all()
rm(list = ls())
devtools::load_all()
# the necessasry paths
database_folder = "../inst/extdata"
attribute_db = "test"
dictionary_db = "dict_db"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
# the necessasry paths
database_folder = "../inst/extdata"
attribute_db = "test"
dictionary_db = "dict_db"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
make_shapefile = function(database_dir=NULL,
attribute_database_name=NULL,
dictionary_database_name=NULL,
shapefile=NULL,
attri=NULL,
joins="") {
# establish connections
conns = set_connection(database_dir)
# set the right ones
# there are some issues with indexing the list, for some reason we need to index conns with [[]]
# to maintain a valid and open connection
index_attr = which(grepl(attribute_database_name, names(conns)))
if (!is.null(dictionary_database_name)) {
index_dict = which(grepl(dictionary_database_name, names(conns)))
}
attr_database_conn = conns[[index_attr]]
if (!is.null(dictionary_database_name)) {
dict_database_conn = conns[[index_dict]]
}
# the table names are the attributes we can query
# Especially the one in the attributes table are interesting
table_names_attr = make_vector_table_names(attr_database_conn)
if (!is.null(dictionary_database_name)) {
table_names_dict = make_vector_table_names(dict_database_conn)
}
# create a csv file of the names of the databases
# write_csvs(table_names = table_names, database_dir = database_dir)
# make a list of dataframes(tables) for the attributes database
dfs_attr = make_list_dataframes(attr_database_conn)
# make a list of dataframes(tables) for the dictionary database
if (!is.null(dictionary_database_name_name)) {
dfs_dict = make_list_dataframes(dict_database_conn)
}
# check for each dataframe if they have an id and subid column
log_vec = check_id(dfs_attr)
# for the rest create the iffi index for the attribute tables
dfs_attr_iffi = create_iffi_index(dfs_attr, log_vec)
# find the tables that we can join directly
tables_to_append_diretly = find_tables(dfs_attr_iffi, attri)
### join those tables
# read the shape
shape = read_shape(shapefile)
shape_joined_attri = join_shape_attributes(shape, tables_to_append_diretly, dfs_attr_iffi)
# make the joins to the dictionary
if (!is.null(dictionary_database_name)) {
joined_dicionary_tables_with_iffi_kodex = join_descriptions(joins, dfs_attr_iffi, dfs_dict)
}
# join them to the shape
if (!is.null(dictionary_database_name)) {
final_joined = join_descriptions_shape(joined_dicionary_tables_with_iffi_kodex, shape_joined_attri)
}
# filter the columns we wanted
final_selected = select_cols(final_joined, attri, joins)
return(final_selected)
}
database_folder = "../inst/extdata"
attribute_db = "test"
dictionary_db = "dict_db"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
traceback()
database_dir
database_dir = database_folder,
# the necessasry paths
database_folder = "../inst/extdata"
attribute_db = "test"
dictionary_db = "dict_db"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
database_dir = database_folder,
database_dir = database_folder
database_dir
attribute_database_name = attribute_db
dictionary_database_name = dictionary_db
shape = shape
attri=attri
# establish connections
conns = set_connection(database_dir)
conns
library(here)
here::i_am()
here::i_am("example1.Rmd")
here(database_folder)
library(here)
rm(list=ls())
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
```{r setup}
library(iffitoR)
library(here)
# the necessasry paths
database_folder = "../inst/extdata"
attribute_db = "test"
dictionary_db = "dict_db"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
database_dir = here(database_folder)
database_dir
library(here::i_am(".."))
library(here::i_am("./.."))
library(here::i_am("example1.Rmd"))
library(iffitoR)
library(here)
i_am("example1.Rmd")
database_dir = here(database_folder)
database_dir
here("..", "inst", "extdata")
here::here()
library(iffitoR)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(iffitoR)
# the necessasry paths
database_folder = "../inst/extdata"
attribute_db = "test"
dictionary_db = "dict_db"
shape = "../inst/extdata/IFFI10_1.shp"
attri = c("anno_min", "mese_min")
res_sf = make_shapefile(database_dir = database_folder,
attribute_database_name = attribute_db,
dictionary_database_name = dictionary_db,
shape = shape,
attri=attri)
