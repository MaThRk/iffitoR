attri=NULL,
joins=NULL) {
# establish connections
conns = set_connection(database_dir)
# set the right ones
# there are some issues with indexing the list, for some reason we need to index conns with [[]]
# to maintain a valid and open connection
index_attr = which(grepl(attribute_database_name, names(conns)))
if (!is.null(dictionary_database_name)) {
index_dict = which(grepl(dictionary_database_name, names(conns)))
}
attr_database_conn = conns[[index_attr]]
if (!is.null(dictionary_database_name)) {
dict_database_conn = conns[[index_dict]]
}
return(conns)
# the table names are the attributes we can query
# Especially the one in the attributes table are interesting
table_names_attr = make_vector_table_names(attr_database_conn)
if (!is.null(dictionary_database_name)) {
table_names_dict = make_vector_table_names(dict_database_conn)
}
# create a csv file of the names of the databases
# write_csvs(table_names = table_names, database_dir = database_dir)
# make a list of dataframes(tables) for the attributes database
dfs_attr = make_list_dataframes(attr_database_conn)
# make a list of dataframes(tables) for the dictionary database
if (!is.null(dictionary_database_name)) {
dfs_dict = make_list_dataframes(dict_database_conn)
}
# check for each dataframe if they have an id and subid column
log_vec = check_id(dfs_attr)
# for the rest create the iffi index for the attribute tables
dfs_attr_iffi = create_iffi_index(dfs_attr, log_vec)
# find the tables that we can join directly
tables_to_append_diretly = find_tables(dfs_attr_iffi, attri)
### join those tables
# read the shape
shape = read_shape(shapefile)
shape_joined_attri = join_shape_attributes(shape, tables_to_append_diretly, dfs_attr_iffi)
# make the joins to the dictionary
if (!is.null(dictionary_database_name) | !is.null(joins)) {
joined_dicionary_tables_with_iffi_kodex = join_descriptions(joins, dfs_attr_iffi, dfs_dict)
}
# join them to the shape
if (!is.null(dictionary_database_name) | !is.null(joins)) {
final_joined = join_descriptions_shape(joined_dicionary_tables_with_iffi_kodex, shape_joined_attri)
}
# filter the columns we wanted
final_selected = select_cols(final_joined, attri, joins)
return(final_selected)
}
res_sf = make_shapefile(database_dir = "data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
devtools::load_all()
res_sf = make_shapefile(database_dir = "data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
res_sf
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
rm(list=ls())
devtools::load_all()
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
res_sf
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
library(iffitoR)
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = ".",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(iffitoR)
library(RODBC)
library(dplyr)
library(tools)
library(stringr)
library(sf)
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = ".",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(iffitoR)
library(RODBC)
library(dplyr)
library(tools)
library(stringr)
library(sf)
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
remove.packages("iffitoR")
devtools::install_github("RobinKohrs/iffitoR")
library(iffitoR)
res = iffitoR::make_shapefile(database_dir = "vignettes/data/", attribute_database_name = "test", dictionary_database_name = "dic_db", shapefile = "vignettes/data/IFFI10_1.shp", attri = c("anno_min", "mese_min"))
class(res)
plot(res)
head(res)
pkgdown::build_site()
rm(list=ls())
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
rm(list = ls())
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
library(iffitoR)
library(RODBC)
library(dplyr)
library(tools)
library(stringr)
library(sf)
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
library(ggplot2)
names(res_sf)
nrow(res_sf)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen")
res_gg
res_sf %>% filter(anno_min > 1990)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey")
res_gg
res_sf = res_sf %>% filter(anno_min > 2000)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", Name="Year")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", name="Year")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", name="Year") +
scale_colour_manual(values=NA) +
guides(colour=guide_legend("No data", override.aes = list(colour="grey")))
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", name="Year") +
scale_colour_manual(values=NA) +
guides(colour=guide_legend("No data", override.aes = list(colour="grey")))
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", Name="Year")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", Name="Year")
res_gg
library(ggplot2)
res_sf = res_sf %>% filter(anno_min > 2000)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", Name="Year")
library(ggplot2)
res_sf = res_sf %>% filter(anno_min > 2000)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", name="year")
res_gg
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
devtools::build_vignettes()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
devtools::build_vignettes()
devtools::build_vignettes()
pkgdown::build_site()
make_shapefile = function(database_dir=NULL,
attribute_database_name=NULL,
dictionary_database_name=NULL,
shapefile=NULL,
attri=NULL,
joins=NULL) {
# establish connections
conns = set_connection(database_dir)
# set the right ones
# there are some issues with indexing the list, for some reason we need to index conns with [[]]
# to maintain a valid and open connection
index_attr = which(grepl(attribute_database_name, names(conns)))
if (!is.null(dictionary_database_name)) {
index_dict = which(grepl(dictionary_database_name, names(conns)))
}
attr_database_conn = conns[[index_attr]]
if (!is.null(dictionary_database_name)) {
dict_database_conn = conns[[index_dict]]
}
# the table names are the attributes we can query
# Especially the one in the attributes table are interesting
table_names_attr = make_vector_table_names(attr_database_conn)
if (!is.null(dictionary_database_name)) {
table_names_dict = make_vector_table_names(dict_database_conn)
}
# create a csv file of the names of the databases
# write_csvs(table_names = table_names, database_dir = database_dir)
# make a list of dataframes(tables) for the attributes database
dfs_attr = make_list_dataframes(attr_database_conn)
# make a list of dataframes(tables) for the dictionary database
if (!is.null(dictionary_database_name)) {
dfs_dict = make_list_dataframes(dict_database_conn)
}
# check for each dataframe if they have an id and subid column
log_vec = check_id(dfs_attr)
# for the rest create the iffi index for the attribute tables
dfs_attr_iffi = create_iffi_index(dfs_attr, log_vec)
# find the tables that we can join directly
tables_to_append_diretly = find_tables(dfs_attr_iffi, attri)
### join those tables
# read the shape
shape = read_shape(shapefile)
shape_joined_attri = join_shape_attributes(shape, tables_to_append_diretly, dfs_attr_iffi)
# make the joins to the dictionary
if (!is.null(dictionary_database_name) | !is.null(joins)) {
joined_dicionary_tables_with_iffi_kodex = join_descriptions(joins, dfs_attr_iffi, dfs_dict)
}
# join them to the shape
if (!is.null(dictionary_database_name) | !is.null(joins)) {
final_joined = join_descriptions_shape(joined_dicionary_tables_with_iffi_kodex, shape_joined_attri)
}
# filter the columns we wanted
final_selected = select_cols(final_joined, attri, joins)
return(final_selected)
}
make_shapefile(
database_dir = "data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
devtools::load_all()
rm(list = ls())
make_shapefile(
database_dir = "data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
make_shapefile(
database_dir = "../euracR/data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
make_shapefile(
database_dir = "../euracR/data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
database_dir = "../euracR/data/database/"
attribute_database_name = "tbl_frane"
dictionary_database_name = "diz_frane"
make_shapefile(
database_dir = "../euracR/data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "../euracR/data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
shapefile = "../euracR/data/Shapefiles/IFFI10_1.shp"
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
)
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
)
# establish connections
conns = set_connection(database_dir)
conns
# set the right ones
# there are some issues with indexing the list, for some reason we need to index conns with [[]]
# to maintain a valid and open connection
index_attr = which(grepl(attribute_database_name, names(conns)))
index_attr
if (!is.null(dictionary_database_name)) {
index_dict = which(grepl(dictionary_database_name, names(conns)))
}
index_dict
attr_database_conn = conns[[index_attr]]
library(roxygen2)
devtools::load_all()
devtools::load_all()
devtools::document()
conns
devtools::document()
remove.packages("iffitoR")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(iffitoR)
connections = iffitoR::set_connection(".")
devtools::build_vignettes()
pkgdown::build_site()
pkgdown::build_site()
vignette("example1", package = "iffitoR")
