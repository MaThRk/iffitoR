attri=c("anno_min", "mese_min"))
library(iffitoR)
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = ".",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(iffitoR)
library(RODBC)
library(dplyr)
library(tools)
library(stringr)
library(sf)
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = ".",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(iffitoR)
library(RODBC)
library(dplyr)
library(tools)
library(stringr)
library(sf)
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
remove.packages("iffitoR")
devtools::install_github("RobinKohrs/iffitoR")
library(iffitoR)
res = iffitoR::make_shapefile(database_dir = "vignettes/data/", attribute_database_name = "test", dictionary_database_name = "dic_db", shapefile = "vignettes/data/IFFI10_1.shp", attri = c("anno_min", "mese_min"))
class(res)
plot(res)
head(res)
pkgdown::build_site()
rm(list=ls())
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
rm(list = ls())
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
library(iffitoR)
library(RODBC)
library(dplyr)
library(tools)
library(stringr)
library(sf)
res_sf = make_shapefile(database_dir = "vignettes/data/",
attribute_database_name = "test",
dictionary_database_name = "dic_db",
shape = "vignettes/data/IFFI10_1.shp",
attri=c("anno_min", "mese_min"))
library(ggplot2)
names(res_sf)
nrow(res_sf)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen")
res_gg
res_sf %>% filter(anno_min > 1990)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey")
res_gg
res_sf = res_sf %>% filter(anno_min > 2000)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", Name="Year")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", name="Year")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", name="Year") +
scale_colour_manual(values=NA) +
guides(colour=guide_legend("No data", override.aes = list(colour="grey")))
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", name="Year") +
scale_colour_manual(values=NA) +
guides(colour=guide_legend("No data", override.aes = list(colour="grey")))
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", Name="Year")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", Name="Year")
res_gg
library(ggplot2)
res_sf = res_sf %>% filter(anno_min > 2000)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", Name="Year")
library(ggplot2)
res_sf = res_sf %>% filter(anno_min > 2000)
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey")
res_gg
res_gg = ggplot(res_sf) +
geom_sf(aes(color=anno_min)) +
scale_color_continuous(low="white", high="darkgreen", na.value="grey", name="year")
res_gg
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
devtools::build_vignettes()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
devtools::build_vignettes()
devtools::build_vignettes()
pkgdown::build_site()
make_shapefile = function(database_dir=NULL,
attribute_database_name=NULL,
dictionary_database_name=NULL,
shapefile=NULL,
attri=NULL,
joins=NULL) {
# establish connections
conns = set_connection(database_dir)
# set the right ones
# there are some issues with indexing the list, for some reason we need to index conns with [[]]
# to maintain a valid and open connection
index_attr = which(grepl(attribute_database_name, names(conns)))
if (!is.null(dictionary_database_name)) {
index_dict = which(grepl(dictionary_database_name, names(conns)))
}
attr_database_conn = conns[[index_attr]]
if (!is.null(dictionary_database_name)) {
dict_database_conn = conns[[index_dict]]
}
# the table names are the attributes we can query
# Especially the one in the attributes table are interesting
table_names_attr = make_vector_table_names(attr_database_conn)
if (!is.null(dictionary_database_name)) {
table_names_dict = make_vector_table_names(dict_database_conn)
}
# create a csv file of the names of the databases
# write_csvs(table_names = table_names, database_dir = database_dir)
# make a list of dataframes(tables) for the attributes database
dfs_attr = make_list_dataframes(attr_database_conn)
# make a list of dataframes(tables) for the dictionary database
if (!is.null(dictionary_database_name)) {
dfs_dict = make_list_dataframes(dict_database_conn)
}
# check for each dataframe if they have an id and subid column
log_vec = check_id(dfs_attr)
# for the rest create the iffi index for the attribute tables
dfs_attr_iffi = create_iffi_index(dfs_attr, log_vec)
# find the tables that we can join directly
tables_to_append_diretly = find_tables(dfs_attr_iffi, attri)
### join those tables
# read the shape
shape = read_shape(shapefile)
shape_joined_attri = join_shape_attributes(shape, tables_to_append_diretly, dfs_attr_iffi)
# make the joins to the dictionary
if (!is.null(dictionary_database_name) | !is.null(joins)) {
joined_dicionary_tables_with_iffi_kodex = join_descriptions(joins, dfs_attr_iffi, dfs_dict)
}
# join them to the shape
if (!is.null(dictionary_database_name) | !is.null(joins)) {
final_joined = join_descriptions_shape(joined_dicionary_tables_with_iffi_kodex, shape_joined_attri)
}
# filter the columns we wanted
final_selected = select_cols(final_joined, attri, joins)
return(final_selected)
}
make_shapefile(
database_dir = "data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
devtools::load_all()
rm(list = ls())
make_shapefile(
database_dir = "data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
make_shapefile(
database_dir = "../euracR/data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
make_shapefile(
database_dir = "../euracR/data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
database_dir = "../euracR/data/database/"
attribute_database_name = "tbl_frane"
dictionary_database_name = "diz_frane"
make_shapefile(
database_dir = "../euracR/data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "../euracR/data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
))
shapefile = "../euracR/data/Shapefiles/IFFI10_1.shp"
attri = c(
"anno_min",
"anno_max",
"giorno_min",
"giorno_max",
"toponimo",
"costo_eff_inteventi"
)
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
)
# establish connections
conns = set_connection(database_dir)
conns
# set the right ones
# there are some issues with indexing the list, for some reason we need to index conns with [[]]
# to maintain a valid and open connection
index_attr = which(grepl(attribute_database_name, names(conns)))
index_attr
if (!is.null(dictionary_database_name)) {
index_dict = which(grepl(dictionary_database_name, names(conns)))
}
index_dict
attr_database_conn = conns[[index_attr]]
library(roxygen2)
devtools::load_all()
devtools::load_all()
devtools::document()
conns
devtools::document()
remove.packages("iffitoR")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(iffitoR)
connections = iffitoR::set_connection(".")
devtools::build_vignettes()
pkgdown::build_site()
pkgdown::build_site()
vignette("example1", package = "iffitoR")
devtools::build_vignettes()
devtools::build_vignettes()
pkgdown::build_site()
remove.packages("iffitoR")
devtools::install_github("RobinKohrs/iffitoR")
library(mapview)
library(mapview)
library(ggplot2)
library(dplyr)
library(plyr)
library(iffitoR)
library(sf)
res_raw = make_shapefile(
database_dir = "../euracR/data/database/",
# normally null only setting it here for me
attribute_database_name = "tbl_frane",
# the name without extension
dictionary_database_name = "diz_frane",
shapefile = "../euracR/data/Shapefiles/IFFI10_1.shp",
# normally null only setting it here for me
# the colums we want to retrieve directly
attri = c(
"anno_min",
"anno_max",
"mese_min",
"mese_max",
"giorno_min",
"giorno_max"
),
# tables to join the description
joins = list(
"tbl_frane.Geologia.litologia" = c(
"diz_frane.diz_litologie.litologia",
"diz_frane.diz_litologie.nome_litologia"
),
"tbl_frane.clas_ii_liv.movimento" = c(
"diz_frane.diz_movimenti.movimento",
"diz_frane.diz_movimenti.nome_movimento"
),
"tbl_frane.Uso_Suolo.uso_suolo" = c(
"diz_frane.diz_usi_suolo.uso_suolo",
"diz_frane.diz_usi_suolo.nome_uso_suolo"
)
)
)
# filter all samples that have at least one for each, so we have a full date
res_filtered = res_raw %>%
dplyr::filter(
!is.na(anno_min) | !is.na(anno_max),
!is.na(mese_min) | !is.na(mese_max),
!is.na(giorno_min) | !is.na(giorno_max)
) %>%
distinct(PIFF_ID, .keep_all = TRUE)
res_no_date = res_raw %>% filter(!PIFF_ID %in% res_filtered$PIFF_ID) %>%
distinct(PIFF_ID, .keep_all = TRUE)
# build a date
res_date = res_filtered %>% mutate(
year = if_else(!is.na(anno_min), true = anno_min, false = anno_max),
month = if_else(!is.na(mese_min), true = mese_min, false = mese_max),
day = if_else(!is.na(giorno_min), true = giorno_min, false = giorno_max)
) %>% mutate(date = paste(year, month, day, sep = "/")) %>%
mutate(date = as.Date(date),
year.int = year,
year.posix = as.Date(paste0(year, "-01-01")))
# check that there are no more NAs
res_date %>%  select(c(year.posix, month, day)) %>% st_drop_geometry(.) %>% purrr::map(~sum(is.na(.)))
# 1900 - now
ggplot(res_date) +
geom_histogram(aes(x = year.posix), fill = "darkred", col = "black") +
scale_x_date(date_breaks = "10 year",
labels = scales::date_format("%Y"),
limits = as.Date(c("1900-01-01", "2020-12-01")))
# 2000 -now
ggplot(res_date, aes(x = year.posix)) +
geom_bar(fill = "grey", col = "black", size=1.2) +
geom_text(aes(label=..count..),
stat='count',
nudge_y = 0.125,
vjust=-1) +
scale_x_date(date_breaks = "1 year",
labels = scales::date_format("%Y"),
limits = as.Date(c("2000-01-02", "2020-12-01"))) +
labs(title="Count of Events of all type",
x = "Year") +
theme_minimal() +
theme(
axis.text.x = element_text(angle=90)
)
# plot it
mv = res_date %>% filter(year > 1900) %>% mapview(zcol = "year.int", at = seq(1900, 2020, 20))
mv
